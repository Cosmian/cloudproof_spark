---
name: Spark CI

on: push

jobs:
  sbt:
    runs-on: ubuntu-22.04

    steps:
      - uses: actions/checkout@v3

      - name: Cache build
        uses: actions/cache@v3
        continue-on-error: false
        with:
          path: |
            ~/.m2/repository
            target
          key: ${{ runner.os }}-maven-${{ hashFiles('**/pom.xml') }}
          restore-keys: |
            ${{ runner.os }}-maven-${{ hashFiles('**/pom.xml') }}

      - uses: actions/setup-python@v2
        with:
          python-version: "3.8"

      - name: Set up JDK 8
        uses: actions/setup-java@v3
        with:
          java-version: 8
          distribution: temurin
          cache: maven

      - uses: vemonet/setup-spark@v1
        with:
          spark-version: 3.3.2
          hadoop-version: 3

      - run: spark-submit --version

      - name: Download dataset
        run: wget https://github.com/datablist/sample-csv-files/raw/main/files/organizations/organizations-100000.csv

      - name: Assembly it and run it
        run: |
          sbt assembly
          spark-submit --class "CloudproofSpark" target/scala-2.12/CloudproofSpark-assembly-1.0.jar

      - run: cat /proc/cpuinfo

      - name: Bench without encryption
        run: |
            sbt "test:testOnly *TestParquet"
            du -bch --apparent-size out.parquet.raw | tail -1

      - name: Bench with AES256-GCM encryption
        run: |
          sbt "test:testOnly *TestParquetAesGcm"
          du -bch --apparent-size out.parquet.aesgcm | tail -1

      - name: Bench with Cloudproof
        run: |
          sbt "test:testOnly *TestCloud*"
          du -bch --apparent-size out.parquet.cover_crypt | tail -1
